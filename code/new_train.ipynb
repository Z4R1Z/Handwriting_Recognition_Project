{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "train set size: 90240, validation set size: 22560\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\Ders\\CS-484\\Proje\\Handwriting_Recongition_Project\\code\\new_train.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 217>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Ders/CS-484/Proje/Handwriting_Recongition_Project/code/new_train.ipynb#ch0000000?line=213'>214</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrain set size: \u001b[39m\u001b[39m{\u001b[39;00msplit_train_size\u001b[39m}\u001b[39;00m\u001b[39m, validation set size: \u001b[39m\u001b[39m{\u001b[39;00msplit_valid_size\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Ders/CS-484/Proje/Handwriting_Recongition_Project/code/new_train.ipynb#ch0000000?line=215'>216</a>\u001b[0m net \u001b[39m=\u001b[39m ConvNet()\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/Ders/CS-484/Proje/Handwriting_Recongition_Project/code/new_train.ipynb#ch0000000?line=216'>217</a>\u001b[0m net \u001b[39m=\u001b[39m net\u001b[39m.\u001b[39;49mcuda()\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Ders/CS-484/Proje/Handwriting_Recongition_Project/code/new_train.ipynb#ch0000000?line=217'>218</a>\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Ders/CS-484/Proje/Handwriting_Recongition_Project/code/new_train.ipynb#ch0000000?line=220'>221</a>\u001b[0m optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mSGD(net\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m, momentum\u001b[39m=\u001b[39m\u001b[39m0.9\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:688\u001b[0m, in \u001b[0;36mModule.cuda\u001b[1;34m(self, device)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Furkan/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=670'>671</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcuda\u001b[39m(\u001b[39mself\u001b[39m: T, device: Optional[Union[\u001b[39mint\u001b[39m, device]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[0;32m    <a href='file:///c%3A/Users/Furkan/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=671'>672</a>\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Furkan/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=672'>673</a>\u001b[0m \n\u001b[0;32m    <a href='file:///c%3A/Users/Furkan/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=673'>674</a>\u001b[0m \u001b[39m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Furkan/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=685'>686</a>\u001b[0m \u001b[39m        Module: self\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Furkan/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=686'>687</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Furkan/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=687'>688</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(\u001b[39mlambda\u001b[39;49;00m t: t\u001b[39m.\u001b[39;49mcuda(device))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:578\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Furkan/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=575'>576</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[0;32m    <a href='file:///c%3A/Users/Furkan/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=576'>577</a>\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> <a href='file:///c%3A/Users/Furkan/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=577'>578</a>\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    <a href='file:///c%3A/Users/Furkan/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=579'>580</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    <a href='file:///c%3A/Users/Furkan/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=580'>581</a>\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    <a href='file:///c%3A/Users/Furkan/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=581'>582</a>\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Furkan/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=582'>583</a>\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Furkan/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=587'>588</a>\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Furkan/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=588'>589</a>\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:578\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Furkan/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=575'>576</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[0;32m    <a href='file:///c%3A/Users/Furkan/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=576'>577</a>\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> <a href='file:///c%3A/Users/Furkan/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=577'>578</a>\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    <a href='file:///c%3A/Users/Furkan/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=579'>580</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    <a href='file:///c%3A/Users/Furkan/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=580'>581</a>\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    <a href='file:///c%3A/Users/Furkan/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=581'>582</a>\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Furkan/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=582'>583</a>\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Furkan/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=587'>588</a>\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Furkan/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=588'>589</a>\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:601\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Furkan/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=596'>597</a>\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Furkan/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=597'>598</a>\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Furkan/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=598'>599</a>\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Furkan/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=599'>600</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> <a href='file:///c%3A/Users/Furkan/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=600'>601</a>\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[0;32m    <a href='file:///c%3A/Users/Furkan/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=601'>602</a>\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    <a href='file:///c%3A/Users/Furkan/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=602'>603</a>\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:688\u001b[0m, in \u001b[0;36mModule.cuda.<locals>.<lambda>\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Furkan/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=670'>671</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcuda\u001b[39m(\u001b[39mself\u001b[39m: T, device: Optional[Union[\u001b[39mint\u001b[39m, device]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[0;32m    <a href='file:///c%3A/Users/Furkan/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=671'>672</a>\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Furkan/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=672'>673</a>\u001b[0m \n\u001b[0;32m    <a href='file:///c%3A/Users/Furkan/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=673'>674</a>\u001b[0m \u001b[39m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Furkan/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=685'>686</a>\u001b[0m \u001b[39m        Module: self\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Furkan/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=686'>687</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Furkan/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=687'>688</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply(\u001b[39mlambda\u001b[39;00m t: t\u001b[39m.\u001b[39;49mcuda(device))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\cuda\\__init__.py:210\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Furkan/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/cuda/__init__.py?line=205'>206</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    <a href='file:///c%3A/Users/Furkan/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/cuda/__init__.py?line=206'>207</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/Furkan/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/cuda/__init__.py?line=207'>208</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmultiprocessing, you must use the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mspawn\u001b[39m\u001b[39m'\u001b[39m\u001b[39m start method\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    <a href='file:///c%3A/Users/Furkan/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/cuda/__init__.py?line=208'>209</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(torch\u001b[39m.\u001b[39m_C, \u001b[39m'\u001b[39m\u001b[39m_cuda_getDeviceCount\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m--> <a href='file:///c%3A/Users/Furkan/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/cuda/__init__.py?line=209'>210</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTorch not compiled with CUDA enabled\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    <a href='file:///c%3A/Users/Furkan/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/cuda/__init__.py?line=210'>211</a>\u001b[0m \u001b[39mif\u001b[39;00m _cudart \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Furkan/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/cuda/__init__.py?line=211'>212</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[0;32m    <a href='file:///c%3A/Users/Furkan/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/cuda/__init__.py?line=212'>213</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.transforms import Normalize, ToTensor\n",
    "import torch.nn as nn  # neural network\n",
    "import torch.optim as optim  # optimization layer\n",
    "import torch.nn.functional as F  # activation functions\n",
    "import argparse\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "import pandas as pd\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    '''Define your convolutional neural network'''\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layers = []\n",
    "        self.layers += [nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, stride=1, padding=1)]\n",
    "        self.layers += [nn.BatchNorm2d(64)]\n",
    "        self.layers += [nn.ReLU()]\n",
    "        self.layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        \n",
    "        self.layers += [nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)]\n",
    "        self.layers += [nn.BatchNorm2d(128)]\n",
    "        self.layers += [nn.ReLU()]\n",
    "        self.layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        self.layers += [nn.Dropout(0.3)]\n",
    "        \n",
    "        self.layers += [nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)]\n",
    "        self.layers += [nn.BatchNorm2d(256)]\n",
    "        self.layers += [nn.ReLU()]\n",
    "        self.layers += [nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1)]\n",
    "        self.layers += [nn.BatchNorm2d(256)]\n",
    "        self.layers += [nn.ReLU()]\n",
    "        self.layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "\n",
    "        self.layers += [nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1)]\n",
    "        self.layers += [nn.BatchNorm2d(512)]\n",
    "        self.layers += [nn.ReLU()]\n",
    "        self.layers += [nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1)]\n",
    "        self.layers += [nn.BatchNorm2d(512)]\n",
    "        self.layers += [nn.ReLU()]\n",
    "        self.layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        \n",
    "        self.sq = nn.Sequential(*self.layers)\n",
    "        \n",
    "        self.layers_l = []\n",
    "        self.layers_l += [nn.Linear(512, 256)]\n",
    "        self.layers_l += [nn.ReLU()]\n",
    "        self.layers_l += [nn.Linear(256, 47)]\n",
    "        #self.layers_l += nn.LogSoftmax(dim=1)\n",
    "        self.sq2 = nn.Sequential(*self.layers_l)\n",
    "     \n",
    "    def forward(self, x):\n",
    "        x = self.sq(x)\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.sq2(x)\n",
    "        #x = self.logSoftmax(x)\n",
    "        return x\n",
    "\n",
    "def train(net, optimizer, criterion):\n",
    "    '''\n",
    "    Returns validation loss and accuracy\n",
    "    \n",
    "        Parameters:\n",
    "            net (CNN): a convolutional neural network to train\n",
    "            optimizer: optimizer\n",
    "            criterion (loss function): a loss function to evaluate the model on\n",
    "            args (ArgumentParser): hyperparameters\n",
    "        \n",
    "        Returns:\n",
    "            net (CNN): a trained model\n",
    "            train_loss (float): train loss\n",
    "            train_acc (float): train accuracy\n",
    "    '''\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "    \n",
    "    net.train()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    train_loss = 0\n",
    "    \n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # the class with the highest value is the prediction\n",
    "        _, prediction = torch.max(outputs.data, 1)  # grab prediction as one-dimensional tensor\n",
    "        total += labels.size(0)\n",
    "        correct += (prediction == labels).sum().item()\n",
    "\n",
    "    train_loss = train_loss / len(train_loader)\n",
    "    train_acc = 100 * correct / total\n",
    "    \n",
    "    return net, train_loss, train_acc  # net is returned to be fed to the test function later\n",
    "def validate(net, criterion):\n",
    "    '''\n",
    "    Returns validation loss and accuracy\n",
    "    \n",
    "        Parameters:\n",
    "            net (CNN): a convolutional neural network to validate\n",
    "            criterion (loss function): a loss function to evaluate the model on\n",
    "            args (ArgumentParser): hyperparameters\n",
    "        \n",
    "        Returns:\n",
    "            val_loss (float): validation loss\n",
    "            val_acc (float): validation accuracy\n",
    "    '''\n",
    "    val_loader = torch.utils.data.DataLoader(val_set, batch_size=64, shuffle=True)\n",
    "    \n",
    "    net.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    val_loss = 0 \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in val_loader:\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "            outputs = net(inputs)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            _, prediction = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (prediction == labels).sum().item()\n",
    "\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        val_acc = 100 * correct / total\n",
    "\n",
    "    return val_loss, val_acc\n",
    "\n",
    "def test(net):\n",
    "    '''\n",
    "    Returns test accuracy\n",
    "    \n",
    "        Parameters:\n",
    "            net (CNN): a trained model\n",
    "            args (ArgumentParser): hyperparameters\n",
    "        \n",
    "        Returns:\n",
    "            test_acc (float): test accuracy of a trained model\n",
    "    '''\n",
    "    test_loader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=True)\n",
    "\n",
    "    net.eval()\n",
    "    \n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "            outputs = net(inputs)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            output = (torch.max(torch.exp(outputs), 1)[1]).data.cpu().numpy()\n",
    "            y_pred.extend(output) # Save Prediction\n",
    "        \n",
    "            labels = labels.data.cpu().numpy()\n",
    "            y_true.extend(labels) # Save Truth\n",
    "\n",
    "\n",
    "        test_acc = 100 * correct / total\n",
    "        cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "        classes = ('0','1','2','3','4','5','6','7','8','9','A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','X','W','Y','Z','a','b','d','e','f', 'g', 'h','n','q','r','t')\n",
    "        df_cm = pd.DataFrame(cf_matrix/np.sum(cf_matrix) *10, index = [i for i in classes], columns = [i for i in classes])\n",
    "        print(\"F1 : \", f1_score(y_true,y_pred, average='micro'))\n",
    "        df_cm.to_pickle(\"conf.pkl\")\n",
    "\n",
    "    return test_acc\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "\n",
    "\n",
    "# load data in\n",
    "train_set = datasets.EMNIST(download=True,root=\"data\", split=\"balanced\",\n",
    "                            train=True, transform=transforms.Compose([ToTensor()])\n",
    "                           )\n",
    "test_set = datasets.EMNIST(root=\"data\", split=\"balanced\", \n",
    "                           train=False,transform=transforms.Compose([ToTensor()])\n",
    "                          )\n",
    "entire_trainset = torch.utils.data.DataLoader(train_set, shuffle=True)\n",
    "\n",
    "split_train_size = int(0.8*(len(entire_trainset)))  # use 80% as train set\n",
    "split_valid_size = len(entire_trainset) - split_train_size  # use 20% as validation set\n",
    "\n",
    "train_set, val_set = torch.utils.data.random_split(train_set, [split_train_size, split_valid_size]) \n",
    "\n",
    "print(f'train set size: {split_train_size}, validation set size: {split_valid_size}')\n",
    "\n",
    "net = ConvNet()\n",
    "net = net.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# containers to keep track of statistics\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "time_total = 0\n",
    "    \n",
    "for epoch in range(10):  # number of training to be completed\n",
    "    time_start = time.time()\n",
    "    net, train_loss, train_acc = train(net, optimizer, criterion)\n",
    "    val_loss, val_acc = validate(net, criterion)\n",
    "    time_end = time.time()\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    val_accs.append(val_acc)\n",
    "    \n",
    "    time_duration = round(time_end - time_start, 2)\n",
    "    time_total += time_duration\n",
    "    \n",
    "    # print results of each iteration\n",
    "    print(f'Epoch {epoch+1}, Accuracy(train, validation):{round(train_acc, 2), round(val_acc, 2)}, '\n",
    "            f'Loss(train, validation):{round(train_loss, 4), round(val_loss, 4)}, Time: {time_duration}s')\n",
    "\n",
    "test_acc = test(net)\n",
    "\n",
    "results = OrderedDict()\n",
    "results['train_losses'] = [round(x, 4) for x in train_losses]\n",
    "results['val_losses'] = [round(x, 4) for x in val_losses]\n",
    "results['train_accs'] = [round(x, 2) for x in train_accs]\n",
    "results['val_accs'] = [round(x, 2) for x in val_accs]\n",
    "results['train_acc'] = round(train_acc, 2)\n",
    "results['val_acc'] = round(val_acc, 2)\n",
    "results['test_acc'] = round(test_acc, 2)\n",
    "results['time_total'] = round(time_total, 2)\n",
    "\n",
    "\n",
    "\n",
    "print('Test Accuracy: {}'.format(results['test_acc']))\n",
    "print('Total time duration: {}'.format(results['time_total']))\n",
    "print()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d8a8c919bd6732bc823198b1f46ac0e8ccd3587ce249f818d866e9fc28155d7a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
